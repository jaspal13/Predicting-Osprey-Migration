{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas\n",
    "import math\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "numpy.random.seed(7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### import the dataset (each of the three types and select the required columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 208.           38.7803       25.385     ]\n",
      " [ 209.           38.78033077   26.03      ]\n",
      " [ 210.           38.78035769   25.135     ]\n",
      " ..., \n",
      " [ 325.            9.1481425     8.13      ]\n",
      " [ 326.            8.82693465    7.56      ]\n",
      " [ 327.            9.03829324    8.79      ]]\n"
     ]
    }
   ],
   "source": [
    "#df = pandas.read_csv('avgbirdscountbyidwithdate.csv', usecols=[0,2,4], engine='python', skipfooter=3)\n",
    "\n",
    "#dataframe = df[df[\"ID\"] == 120]\n",
    "#dataframe = dataframe.drop('ID', 1)\n",
    "#dataframe = dataframe[1:]\n",
    "#print dataframe\n",
    "#dataframe = dataframe[\"latitude\":\"latitude\"]\n",
    "dataframe = pandas.read_csv('AvgbirdDataWithWeather.csv', usecols=[0,2,4,5], engine='python', skipfooter=3)\n",
    "dataframe = dataframe[1:]\n",
    "dataset = dataframe.values\n",
    "print dataset\n",
    "dataset = dataset.astype('float32')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normalise the input data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "dataset = scaler.fit_transform(dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split into test and training dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2602, 778)\n"
     ]
    }
   ],
   "source": [
    "train_size = int(len(dataset) * 0.70)\n",
    "test_size = len(dataset) - train_size\n",
    "train, test = dataset[0:train_size,:], dataset[train_size:len(dataset),:]\n",
    "print(len(train), len(test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create the new dataset from the existing dataset (t -> t+1) lookback =1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_dataset(dataset, look_back=1):\n",
    "\tdataX, dataY = [], []\n",
    "\tfor i in range(len(dataset)-look_back-1):\n",
    "\t\ta = dataset[i:(i+look_back), 0:3]\n",
    "\t\tdataX.append(a)\n",
    "\t\tdataY.append(dataset[i + look_back, 1])\n",
    "\treturn numpy.array(dataX), numpy.array(dataY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "x,y = create_dataset(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "look_back = 1\n",
    "trainX, trainY = create_dataset(train, look_back)\n",
    "testX, testY = create_dataset(test, look_back)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reshape it in case where the input dimension is more than 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "total size of new array must be unchanged",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-63-ef3bc3c3790d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrainX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrainX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtrainX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrainX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mtestX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtestX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtestX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtestX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/numpy/core/fromnumeric.pyc\u001b[0m in \u001b[0;36mreshape\u001b[0;34m(a, newshape, order)\u001b[0m\n\u001b[1;32m    222\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mAttributeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    223\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0m_wrapit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'reshape'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnewshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 224\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnewshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    225\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    226\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: total size of new array must be unchanged"
     ]
    }
   ],
   "source": [
    "trainX = numpy.reshape(trainX, (trainX.shape[0], 1, trainX.shape[1]))\n",
    "testX = numpy.reshape(testX, (testX.shape[0], 1, testX.shape[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def smallmodel():\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(4, input_dim=3))\n",
    "    #model.add(Dropout(0.2))\n",
    "    model.add(Dense(1))\n",
    "    model.compile(loss='mean_squared_error', optimizer='adam')\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "18s - loss: 550.3670\n",
      "Epoch 2/30\n",
      "17s - loss: 413.0591\n",
      "Epoch 3/30\n",
      "18s - loss: 278.6007\n",
      "Epoch 4/30\n",
      "15s - loss: 203.6421\n",
      "Epoch 5/30\n",
      "15s - loss: 148.6804\n",
      "Epoch 6/30\n",
      "15s - loss: 106.9117\n",
      "Epoch 7/30\n",
      "15s - loss: 66.0822\n",
      "Epoch 8/30\n",
      "15s - loss: 39.4953\n",
      "Epoch 9/30\n",
      "15s - loss: 24.3931\n",
      "Epoch 10/30\n",
      "15s - loss: 16.0941\n",
      "Epoch 11/30\n",
      "15s - loss: 11.9030\n",
      "Epoch 12/30\n",
      "15s - loss: 9.6819\n",
      "Epoch 13/30\n",
      "15s - loss: 8.8471\n",
      "Epoch 14/30\n",
      "15s - loss: 7.9556\n",
      "Epoch 15/30\n",
      "15s - loss: 7.6823\n",
      "Epoch 16/30\n",
      "15s - loss: 7.4238\n",
      "Epoch 17/30\n",
      "15s - loss: 6.9263\n",
      "Epoch 18/30\n",
      "15s - loss: 6.8177\n",
      "Epoch 19/30\n",
      "15s - loss: 6.9147\n",
      "Epoch 20/30\n",
      "15s - loss: 6.3368\n",
      "Epoch 21/30\n",
      "15s - loss: 6.1355\n",
      "Epoch 22/30\n",
      "15s - loss: 6.4396\n",
      "Epoch 23/30\n",
      "15s - loss: 6.0066\n",
      "Epoch 24/30\n",
      "15s - loss: 5.9780\n",
      "Epoch 25/30\n",
      "15s - loss: 5.9750\n",
      "Epoch 26/30\n",
      "15s - loss: 6.4793\n",
      "Epoch 27/30\n",
      "15s - loss: 6.0387\n",
      "Epoch 28/30\n",
      "15s - loss: 6.1736\n",
      "Epoch 29/30\n",
      "16s - loss: 5.8923\n",
      "Epoch 30/30\n",
      "15s - loss: 5.7363\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f567782fb90>"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = smallmodel()\n",
    "#model.load_weights(\"bird_120_model_weights_withday.h5\",by_name=False)\n",
    "model.fit(trainX, trainY, nb_epoch=30, batch_size=1, verbose=2)\n",
    "#model.save(\"bird_389_model_weights_withday_modified2.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Phase 1 : Predictions on test and training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Score: 2.41 RMSE\n",
      "Test Score: 2.09 RMSE\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# make predictions\n",
    "trainPredict = model.predict(trainX)\n",
    "testPredict = model.predict(testX)\n",
    "# invert predictions\n",
    "#trainPredict = scaler.inverse_transform(trainPredict)\n",
    "#trainY = scaler.inverse_transform([trainY])\n",
    "#testPredict = scaler.inverse_transform(testPredict)\n",
    "#testY = scaler.inverse_transform([testY])\n",
    "# calculate root mean squared error\n",
    "trainScore = math.sqrt(mean_squared_error(trainY, trainPredict[:,0]))\n",
    "print('Train Score: %.2f RMSE' % (trainScore))\n",
    "testScore = math.sqrt(mean_squared_error(testY, testPredict[:,0]))\n",
    "print('Test Score: %.2f RMSE' % (testScore))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Phase 2 : prediction, Re determine the complete dataset through LSTM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "trainPredict =[]\n",
    "t2 = dataset[0][1]\n",
    "\n",
    "trainPredict.append([[t2.tolist()]])\n",
    "#print trainPredict\n",
    "for i in range(3378):\n",
    "    l=[]\n",
    "    l.append([[dataset[i][0],t2,dataset[i][2]]])\n",
    "    #print l\n",
    "    l2 = numpy.asarray(l)\n",
    "    t2 = model.predict(l2)\n",
    "    #print t2.tolist()\n",
    "    trainPredict.append(t2.tolist())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot the graphs and the RMSE values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pandas' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-0788963e6cec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mdatetime\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdatetime\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdates\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mmd\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mdf1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpandas\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'AvgbirdDataWithWeather.csv'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0musecols\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'python'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mskipfooter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;31m#df1 = pandas.read_csv('avgbirdscountbyidwithdate.csv', usecols=[1,4], engine='python', skipfooter=3)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'pandas' is not defined"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as mpatches\n",
    "from datetime import datetime \n",
    "import matplotlib.dates as md\n",
    "df1 = pandas.read_csv('AvgbirdDataWithWeather.csv', usecols=[1], engine='python', skipfooter=3)\n",
    "#df1 = pandas.read_csv('avgbirdscountbyidwithdate.csv', usecols=[1,4], engine='python', skipfooter=3)\n",
    "\n",
    "#dataframe = df1[df1[\"ID\"] == 120]\n",
    "#dataframe = dataframe.drop('ID', 1)\n",
    "#dataframe = dataframe[1:]\n",
    "#df1 = dataframe\n",
    "\n",
    "ax=plt.gca()\n",
    "xfmt = md.DateFormatter('%Y-%m-%d')\n",
    "ax.xaxis.set_major_formatter(xfmt)\n",
    "\n",
    "tme = df1[1:].values.tolist()\n",
    "x = []\n",
    "#print now.strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "for i in tme:\n",
    "    x.append([datetime.strptime(d,\"%Y-%m-%d\") for d in i])\n",
    "print len(x)\n",
    "\n",
    "plt.xticks( rotation=25 )\n",
    "plt.xlabel(\"Date\")\n",
    "plt.ylabel(\"latitude\")\n",
    "y_axis_predicted=[]\n",
    "y_axis_actual=[]\n",
    "y_axis_actual_test=[]\n",
    "x_axis=[]\n",
    "#print trainPredict[100][0][0]\n",
    "for i in range(3378):\n",
    "    if i==0:\n",
    "        continue\n",
    "    x_axis.append([datetime.strptime(d,\"%Y-%m-%d\") for d in tme[i]])\n",
    "    #print trainPredict[i][0][0]\n",
    "    y_axis_predicted.append(trainPredict[i][0][0])\n",
    "    y_axis_actual.append(dataset[i][1])\n",
    "    #y_axis_actual.append(trainX[i][0][1])\n",
    "    #y_axis_actual.append(testX[i][0][1])\n",
    "trainScore = math.sqrt(mean_squared_error(y_axis_actual, y_axis_predicted))\n",
    "print('Train Score: %.2f RMSE' % (trainScore))\n",
    "plt.plot(x_axis,y_axis_predicted,color = 'r',label = 'Predicted using lstm')\n",
    "plt.plot(x_axis,y_axis_actual,color= 'g',label = 'Original dataset')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.ylim([-15, 50])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from datetime import datetime \n",
    "import matplotlib.dates as md"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'numpy' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-8acca608e331>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrainPredictPlot\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mempty_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mtrainPredictPlot\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnan\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mtrainPredictPlot\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlook_back\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrainPredict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mlook_back\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrainPredict\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# shift test predictions for plotting\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mtestPredictPlot\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mempty_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'numpy' is not defined"
     ]
    }
   ],
   "source": [
    "trainPredictPlot = numpy.empty_like(dataset)\n",
    "trainPredictPlot[:, :] = numpy.nan\n",
    "trainPredictPlot[look_back:len(trainPredict)+look_back, :] = trainPredict\n",
    "# shift test predictions for plotting\n",
    "testPredictPlot = numpy.empty_like(dataset)\n",
    "testPredictPlot[:, :] = numpy.nan\n",
    "testPredictPlot[len(trainPredict)+(look_back*2)+1:len(dataset)-1, :] = testPredict\n",
    "# plot baseline and predictions\n",
    "#plt.plot(scaler.inverse_transform(dataset))\n",
    "plt.plot(trainPredictPlot)\n",
    "plt.plot(testPredictPlot)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
